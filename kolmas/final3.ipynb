{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S09Ff2yUb-6p"
   },
   "source": [
    "# Keeletehnoloogia 3. kodutöö - autori ennustamine\n",
    "Programmile antakse kolme autori ingliskeelsed korpused, mis on lihtsad tekstifailid, kuhu on ilma igasuguse märgenduseta järjest kirjutatud autori eri teosed (ehk siis eeltöötluse tuleb ise teha). Mudel peab antud uue (korpusevälise) lause põhjal ennustama, kes oli selle lause autor.  \n",
    "Kirjuta valmis funktsioonid *train* ja *predict* nii, et kaasasolev testplokk korrektselt töötaks. Muid plokke ja funktsioone võib lisada ja kustutada, kuid väljatrükid ja suured arvutused hoitagu testploki sees.  \n",
    "  \n",
    "**NB!** Ärge kirjutage sisse täisteid, kommenteerige oma koodi, jooksutage enne esitamist nullist läbi ja ärge unustage ülesande esitamisel *Moodle'i* tekstikasti oma mudeli inimloetavat kirjeldust panna. Edu!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12JRjDvyZ2LY"
   },
   "source": [
    "**Impordid** - lisage, mis hing ihaldab, kuni neid eraldi installima ei pea. EstNLTK ja muu 0. praktikumis läbi käinu võib muidugi olla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ukbgXyJzZ1tn"
   },
   "outputs": [],
   "source": [
    "# Sisuliselt kõik samad asjad mis prakitkumis kasutati\n",
    "from time import time\n",
    "# Regex failide mugavamaks sisselugemiseks\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0hYLCf2ZunW"
   },
   "source": [
    "## Treenimine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktsioon andmete treening-, test-, ja valideerimishulgaks jagamiseks\n",
    "# Lõppversioonis 90% andmetest treenimiseks, ja 10% võrdselt jagatud test- ja valideerimishulga vahel\n",
    "# Kokkuvõttes siis: 90% andmetest treenimishulk, 5% valideerimishulk ja 5% testhulk\n",
    "def distribute(length):\n",
    "    train = int(round(length*0.9))\n",
    "    test = train + int(round((length-train)*0.5))\n",
    "    # Tagastan ainult treenimis- ja testhulga alguste indeksid, kuna\n",
    "    # pythoni listi tükeldamise abil saame valideerimishulga kätte\n",
    "    # võttes nendevahelised andmed\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, target, tok=None):\n",
    "    # Loome tokenizeri, kui seda veel pole, ning\n",
    "    # kasutame seda ka test- ja valideerimishulgal\n",
    "    # sisuliselt täpselt sama mis praktikumi kolmandas osas tehtud sai\n",
    "    if tok is None:\n",
    "        tok = Tokenizer(char_level=False)\n",
    "        tok.fit_on_texts(data)\n",
    "        \n",
    "    sent_seqs = tok.texts_to_sequences(data)\n",
    "    X = sequence.pad_sequences(sent_seqs, maxlen=30)\n",
    "    return X, to_categorical(target, num_classes=3), tok\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4NZ1ChSdZpXj"
   },
   "outputs": [],
   "source": [
    "def train(fail1, fail2, fail3):\n",
    "    # Sisendiks: kolme faili nimed\n",
    "    # Kõigepealt loon 2 listi, texts ja labels, texts listi lisan järjest kõik korpused\n",
    "    # lausestatud kujul nii, et kõigepealt eemaldan reavahetused ja seejärel mitmekordsed tühikud\n",
    "    # labels listi panen vastava korpuse autori indeksi\n",
    "    texts = list()\n",
    "    labels = list()\n",
    "    failid = [fail1, fail2, fail3]\n",
    "    for i in range(len(failid)):\n",
    "        with open(failid[i], 'r', encoding='utf-8') as f:\n",
    "            texts.append(nltk.sent_tokenize(re.sub('\\s+', ' ', f.read().replace('\\n', ' '))))\n",
    "            labels.append(i)\n",
    "    \n",
    "    # Tasakaalustan andmed leides kõige väiksema korpuse suuruse\n",
    "    # Idee seisneb pikemate korpuste lõppude ära lõikamises, et oleks aus\n",
    "    # segan eelnevalt pikema korpuse laused suvaliselt\n",
    "    # siin ei kaota me autorite indekseid, sest me ei sega texts listi kuidagi\n",
    "    # vaid texts listi sees olevaid lausestatud korpusi\n",
    "    unbiased = list()\n",
    "    shortest = 10000000\n",
    "    for elem in texts:\n",
    "        if len(elem) < shortest:\n",
    "            shortest = len(elem)\n",
    "    for elem in texts:\n",
    "        random.shuffle(elem)\n",
    "        if len(elem) >= shortest:\n",
    "            unbiased.append(elem[:shortest])\n",
    "    \n",
    "    # Seon korpused neile vastava autori indeksiga\n",
    "    labelled_texts = zip(unbiased, labels)\n",
    "    \n",
    "    # Loon 2 listi, sentences listi panen\n",
    "    # järjest lauseid ja y listi vastavale indeksile\n",
    "    # vastava korpuse autori indeksi\n",
    "    sentences = []\n",
    "    y = []\n",
    "    for item, cls in labelled_texts:\n",
    "        sentences.extend(item)\n",
    "        y.extend([cls] * len(item))\n",
    "    \n",
    "    # Segan mõlemad listid ilma lause -> autor suhet rikkumata\n",
    "    c = list(zip(sentences, y))\n",
    "    random.shuffle(c)\n",
    "    sentences, y = zip(*c)\n",
    "    \n",
    "    # Leian distribute funktsiooni abil vastavalt andmestiku suurusele\n",
    "    # indeksit jaotamaks need treenimis-, test- ja valideerimishulkadeks\n",
    "    train, test = distribute(len(sentences))\n",
    "    X_train = sentences[:train]\n",
    "    y_train = y[:train]\n",
    "    X_val = sentences[train:test]\n",
    "    y_val = y[train:test]\n",
    "    X_test = sentences[test:]\n",
    "    y_test = y[test:]\n",
    "    \n",
    "    # Siin viin saadud hulgad vastavalt praktikumis nähtule\n",
    "    # närvivõrgule seeditavale kujule\n",
    "    X_train_proc, y_train_proc, tok = preprocess(X_train, y_train)\n",
    "    X_val_proc, y_val_proc,  _  = preprocess(X_val, y_val, tok)\n",
    "    X_test_proc, y_test_proc,  _  = preprocess(X_test, y_test, tok)\n",
    "    \n",
    "    # Närvivõrgule ette antava sõnastiku suurus, koos nulliga +1\n",
    "    vocabulary_size = len(tok.word_index) + 1\n",
    "    \n",
    "    # Loon mudeli mis võtab sisendiks järjendi\n",
    "    model = Sequential()\n",
    "    # Embedding kihis määran lause pikkuseks sõnastiku suuruseks enne arvutatud\n",
    "    # suuruse, leidsin kõige parema täpsuse kolme peidetud LSTM kihiga\n",
    "    # Ülejäänud mudeli konstruktsioon sarnaselt praktikumile,\n",
    "    # lisaks otsustasin kasutada täpselt 4 epohhi, kuna valideerimisandmestikuga\n",
    "    # hakkas pärast neljandat epohhi täpsus vähenema, ning treenimishulgaga\n",
    "    # saadi juba ligi 95% niikuinii kätte\n",
    "    model.add(Embedding(vocabulary_size, 30, input_length=30))\n",
    "    model.add(LSTM(60, return_sequences=True))\n",
    "    model.add(LSTM(60, return_sequences=True))\n",
    "    model.add(LSTM(60, return_sequences=False))\n",
    "    model.add(Dense(len(failid), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(X_train_proc, y_train_proc, epochs=4, batch_size=64, validation_data=(X_val_proc, y_val_proc))\n",
    "    tulemus = model.evaluate(X_test_proc, y_test_proc)\n",
    "    print(tulemus)\n",
    "    print(\"Testhulgal oli täpsus {0}%, kaofunktsiooni väärtus {1}.\".format(100*tulemus[1],round(tulemus[0],6)))\n",
    "    \n",
    "    # Salvestan mudeli mugavamaks taaskasutamiseks\n",
    "    model.save(\"lauseKlassifitseerija.h5\")\n",
    "    # Tagasta mudel (nt närvivõrk), mis suudab ennustada, millisesse kolmest failist võiks lause kuuluda.\n",
    "    # Tagastan mudeli ja tokenizeri ennustamiseks\n",
    "    return (model, tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIpc0wmRZpBD"
   },
   "source": [
    "## Ennustamine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "s-6bp46cROUL"
   },
   "outputs": [],
   "source": [
    "def predict(mudel, lause):\n",
    "    # Sisendiks: \n",
    "    # mudel - meetodi 'train' tagastatud mudel\n",
    "    # lause - klassifitseerimist vajav string, sõnestamata puhtal kujul\n",
    "    # viin lause närvivõrgule seeditavale kujule\n",
    "    lause = mudel[1].texts_to_sequences([lause])\n",
    "    # Ennustan autori indeksi algsest autorite nimekirjast\n",
    "    ennustus = mudel[0].predict_classes(lause)\n",
    "    # Tagasta klass - täisarvuline väärtus hulgast {1,2,3}\n",
    "    # Kuna tagastama peab väärtuse hulgast {1, 2, 3} ja minu mudel\n",
    "    # tagastab vastava indeksi autorite listist, mille pikkus on 3,\n",
    "    # siis õige klassi saamiseks liidan ennustatud väärtusele 1.\n",
    "    return ennustus[0]+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkHWAjrhZj0R"
   },
   "source": [
    "## Testimine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmt26INGRfXz",
    "outputId": "ffa47108-8f04-46bb-c4e5-ff27e1da8d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 30)            968370    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 60)            21840     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 60)            29040     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60)                29040     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 183       \n",
      "=================================================================\n",
      "Total params: 1,048,473\n",
      "Trainable params: 1,048,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "720/720 [==============================] - 41s 57ms/step - loss: 0.4789 - accuracy: 0.7952 - val_loss: 0.3205 - val_accuracy: 0.8742\n",
      "Epoch 2/4\n",
      "720/720 [==============================] - 41s 58ms/step - loss: 0.2334 - accuracy: 0.9112 - val_loss: 0.3108 - val_accuracy: 0.8750\n",
      "Epoch 3/4\n",
      "720/720 [==============================] - 42s 58ms/step - loss: 0.1661 - accuracy: 0.9388 - val_loss: 0.3041 - val_accuracy: 0.8824\n",
      "Epoch 4/4\n",
      "720/720 [==============================] - 42s 58ms/step - loss: 0.1380 - accuracy: 0.9480 - val_loss: 0.3463 - val_accuracy: 0.8797\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3369 - accuracy: 0.8929\n",
      "[0.33688509464263916, 0.8929269313812256]\n",
      "Testhulgal oli täpsus 89.29269313812256%, kaofunktsiooni väärtus 0.336885.\n",
      "Treenimiseks kulus 3 minutit ja 0.24 sekundit\n",
      "WARNING:tensorflow:From <ipython-input-5-876f320a9934>:8: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input Tensor(\"embedding_input:0\", shape=(None, 30), dtype=float32), but it was called on an input with incompatible shape (None, 10).\n",
      "Ennustamiseks kulus 1.42 sekundit\n",
      "Vastus:  2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  # Igasugu väljatrükkidega asjad võivad olla siin.\n",
    "\n",
    "  # Treeni nende kolme faili alusel\n",
    "  algusaeg = time()\n",
    "  m = train(\"korpused/janeausten.txt\", \"korpused/shakespeare.txt\", \"korpused/poe.txt\")\n",
    "  aega = time()-algusaeg\n",
    "  print(\"Treenimiseks kulus {} minutit ja {} sekundit\".format(round(aega/60),round(aega%60,2)))\n",
    "  # Meeldetuletuseks: võiks jääda 15 minuti piiridesse\n",
    "\n",
    "  # Ennusta, mis autori teos võiks see lause olla.\n",
    "  algusaeg = time()\n",
    "  vastus = predict(m, \"To be or not to be, that is the question.\") \n",
    "  aega = time()-algusaeg\n",
    "  print(\"Ennustamiseks kulus {} sekundit\".format(round(aega,2)))\n",
    "  # Meeldetuletuseks: võiks jääda 10 sekundi piiridesse\n",
    "  # Loodetavasti on vastuseks 2 - \"shakespeare.txt\"\n",
    "  print(\"Vastus: \",vastus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34u8BqomwFIU"
   },
   "source": [
    "## Mudeli kirjeldus\n",
    "\n",
    "Lähenesin sarnaselt praktikumis soovitatule. Failide sisu vaadates avastasin, et osades on palju tühje ridu, mis sisaldavad ainult reavahetust '\\n' ja mõnes kohas ka liigseid tühikuid, niiet kohe kogu sisu lausestades ei saaks ilmselt eriti häid lauseid. Sellest tulenevalt otsustasin kõigepealt reavahetused asendada tühikutega ning seejärel mitmekordsed tühikud ühe tühikuga. Seejärel tasakaalustasin klassid, lausestasin ja klassifitseerisin lausehaaval. Klassifitseeritud lausetest panin kokku kolm andmehulka: treening-, test- ja valideerimishulk. Mis lõpptulemuses on vastavalt 90, 5 ja 5 %-lise osakaaluga. Otsustasin enda tehtud andmestikujaotuse lõppversiooni sisse jätta, kuna see 10% niikuinii eriti ei tõstaks mu täpsust ja niiviisi saab tunduvalt parema ülevaate mudeli töötamisest. Närvivõrgu parameetreid katsetades jõudsin järelduseni, et kuna antud andmestikus on nii väga pikki kui ka väga lühikesi lauseid, siis ei ole otseselt mõistlik võtta vektori pikkuseks kõige pikema lause pikkust. Keskmise lause pikkuseks ennustasin umbes 30 sõna, millega ka kõige parema tulemuse sain. LSTM kihte lisasin 3 vastavalt praktikumis näidatule, neuronite arvuga mängisin katse-eksituse meetodil ja jätsin need millega parima tulemuse leidsin. Lõpuks salvestasin mudeli failina 'lauseKlassifitseerija.h5'.\n",
    "\n",
    "Joosep Tavits 30/03/2021 01:49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHJM91Vov-Hw"
   },
   "source": [
    "## Tagasiside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr7sHawIwAkX"
   },
   "source": [
    "Leian, et hetkeseisuga minu jaoks on kõige mugavam, kui praktikumides ei eeldata ülesannete kaasa tegemist, kuna mitme ekraani puudumisel on zoomi akent ja lokaalset jupyter notebooki kõrvuti suhteliselt võimatu hallata, kui samal ajal peab keerulistest asjadest ka veel aru saama. Isiklikult on kodutööd aidanud kõike mida praktikumis kuulnud olen, rakendada, ning millestki puudust ei tunne. Lisaks veel mainiks, et täpsuse peale tegemise kodutööd on väga põnevad! :)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "KT_kodutoo_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
